{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t1seo/AIFFEL/blob/master/EXPLORATION/01/%EB%AF%B8%EB%8B%88%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20-%20%EA%B0%80%EC%9C%84%EB%B0%94%EC%9C%84%EB%B3%B4%20%EB%B6%84%EB%A5%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yihuoKWxoJrJ"
      },
      "source": [
        "# 미니 프로젝트 : 가위바위보 분류기를 만들자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIPnwMQn9pz0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z776fZ1oObz"
      },
      "source": [
        "## 1. 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIidF2sOoTD5"
      },
      "source": [
        "### 1-1. 데이터 만들기\n",
        "노트북 카메라를 이용하여 가위, 바위, 보 이미지 각 100장을 만들어본다. 구글의 teachable machine 사이트에서 쉽게 데이터를 만들 수 있다.\n",
        "\n",
        "[https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/)\n",
        "\n",
        "- 여러 각도에서 찍기\n",
        "- 여러 크기로 찍기\n",
        "- 여러 명이 찍기\n",
        "\n",
        "좋은 데이터가 좋은 결과를 낳는다.\n",
        "\n",
        "teachable machine을 통해서 이미지를 저장하면 이미지는 224x224 크기로 되어 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMw68b9CuGDa"
      },
      "source": [
        "### 1-2. 데이터 불러오기 + Resize 하기\n",
        "가위, 바위, 보 이미지를 28x28로 만들어야 한다. 이를 위해 `PIL` 라이브러리를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbGmFo7v8svJ"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL2a2LZW8svK"
      },
      "source": [
        "import os\n",
        "\n",
        "IMG_SIZE = 28 # 이미지 사이즈\n",
        "total_image = 0 # 전체 이미지 개수\n",
        "\n",
        "# 이미지를 리사이즈 해주는 함수\n",
        "def resize_images(img_path):\n",
        "    images=glob.glob(img_path + \"/*.jpg\")\n",
        "    print(f\"{len(images)} images will be resized.\")\n",
        "    \n",
        "    global total_image \n",
        "    total_image += len(images)\n",
        "    \n",
        "    # resize all images to 28x28\n",
        "    target_size=(IMG_SIZE, IMG_SIZE) # 28x28 size\n",
        "    for img in images:\n",
        "        old_img=Image.open(img)\n",
        "        new_img=old_img.resize(target_size, Image.ANTIALIAS)\n",
        "        new_img.save(img, \"JPEG\")\n",
        "        \n",
        "    print(f\"{len(images)} images have been resized.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_qch2838svL"
      },
      "source": [
        "# local\n",
        "# data_dir = os.path.dirname(os.path.abspath('__file__')) # 현재 위치\n",
        "# data_dir += r'/data/' # 데이터 폴더 위치\n",
        "# print(data_dir)\n",
        "\n",
        "# train_path = data_dir + r'train/'\n",
        "# scissor_train_path = train_path + r'scissors/'\n",
        "# rock_train_path = train_path + r'rock/'\n",
        "# paper_train_path = train_path + r'paper/'\n",
        "\n",
        "# train_paths = [scissor_train_path, rock_train_path, paper_train_path]\n",
        "# print(train_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSco03d797F0"
      },
      "source": [
        "## Colab\n",
        "paper_dir = \"/content/drive/MyDrive/data/train/paper\"\n",
        "scissor_dir = \"/content/drive/MyDrive/data/train/scissors\"\n",
        "rock_dir = \"/content/drive/MyDrive/data/train/rock\"\n",
        "\n",
        "img_dir = [scissor_dir, rock_dir, paper_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz4OOB0T8svM"
      },
      "source": [
        "# scissor_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
        "# rock_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
        "# paper_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
        "\n",
        "# # TODO: 폴더 존재하는지 체크해주는 부분 추가\n",
        "\n",
        "# img_dir = [scissor_dir, rock_dir, paper_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUl0eVQM8svN"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for image in tqdm(img_dir):\n",
        "    resize_images(image)\n",
        "    \n",
        "print(f\"총 {total_image} 이미지 resize 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywlnNzab8svN"
      },
      "source": [
        "# 총 이미지 개수\n",
        "print(total_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ARdMF18svN"
      },
      "source": [
        "### 1-3. 가위, 바위, 보 데이터를 읽는 `load_data()` 함수 만들기\n",
        "\n",
        "`load_data()` 함수는 입력으로 이미지가 있는 폴더 위치를 받는다. 여기서는 `rock_scissor_paper` 폴더 위치를 적어주면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52x9vQgA8svO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=300): \n",
        "    \"\"\"    \n",
        "    parameters:\n",
        "        img_path: The directory path of the rock_scissor_paper\n",
        "        number_of_data: The total nubmer of all images. Default value is 300.\n",
        "    return:\n",
        "        image data, label data\n",
        "    \"\"\"\n",
        "    # scissors: 0, rock: 1, paper: 2\n",
        "    img_size = IMG_SIZE\n",
        "    color = 3\n",
        "    \n",
        "    # image data\n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, \n",
        "                    dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
        "    \n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/scissors/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype=np.int32)\n",
        "        imgs[idx, :, :, :] = img # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx] = 0 # 가위 : 0\n",
        "        idx = idx + 1\n",
        "        \n",
        "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype=np.int32)\n",
        "        imgs[idx, :, :, :] = img # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx] = 1 # 바위 : 1\n",
        "        idx = idx + 1\n",
        "    \n",
        "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype=np.int32)\n",
        "        imgs[idx, :, :, :] = img # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx] = 2 # 보 : 2\n",
        "        idx = idx + 1\n",
        "        \n",
        "    print(f\"총 이미지 개수는 {idx} 입니다.\")\n",
        "    return imgs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUyHNoJ-8svO"
      },
      "source": [
        "# train_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "train_data_path = \"/content/drive/MyDrive/data/train\"\n",
        "\n",
        "(X, y) = load_data(train_data_path, number_of_data=3207)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YktJ2y1v8svP"
      },
      "source": [
        "### 1-4. train, test data 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i12dy2XB8svP"
      },
      "source": [
        "# train data와 test data 나누어 주기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E37PMffR8svP"
      },
      "source": [
        "# 정규화\n",
        "X_train = X_train / 255.0   # 입력을 0~1 사이의 값으로 정규화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z53eDGYX8svP"
      },
      "source": [
        "# 이미지 확인 (가위:0, 바위:1, 보:2)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_train[1000])\n",
        "print('라벨: ', y_train[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJbe-e8Q8svQ"
      },
      "source": [
        "## 2. 딥러닝 네트워크 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u7TghGW8svQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# mini VGGNet\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 3), kernel_size=(3, 3), \n",
        "                           filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=256, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmHHphy28svQ"
      },
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 3), kernel_size=(3, 3), \n",
        "#                            filters=16, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2D(kernel_size=(3,3), filters=32, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "#     tf.keras.layers.Dropout(rate=0.5),\n",
        "#     tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=64, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding='valid', activation='relu'),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "#     tf.keras.layers.Dropout(rate=0.5),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(rate=0.5),\n",
        "#     tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(rate=0.5),\n",
        "#     tf.keras.layers.Dense(units=3, activation='softmax') # 10->3\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHFiu2D18svR"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNThRVO_8svR"
      },
      "source": [
        "## 3. 딥러닝 네트워크 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HY8-gRT8svR"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6U_7Iyi8svR"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=25, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrlfOsSW8svS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], marker='.', c='red', label='Train-set Loss')\n",
        "plt.plot(history.history['val_loss'], marker='.', c='blue', label='Validation-set Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g--', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0, 1.2)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_eqV1i08svS"
      },
      "source": [
        "## 4. test 데이터로 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzJD_jHg8svS"
      },
      "source": [
        "X_test = X_test / 255.0 # \n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvyuuEO18svS"
      },
      "source": [
        "predicted_result = model.predict(X_test) # model이 추론한 확률값\n",
        "predicted_labels = np.argmax(predicted_result, axis=1) # 확률의 최대값이 예측하는 숫자를 뜻한다\n",
        "\n",
        "idx = 324\n",
        "print(f\"models.predict() 결과: {predicted_result[idx]}\\n\")\n",
        "print(f\"model이 추론한 가장 가능성이 높은 결과 : \", predicted_labels[idx])\n",
        "print(f\"실제 데이터의 라벨 : \", y_test[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ij-6ks5x8svS"
      },
      "source": [
        "# 실제 이미지 출력\n",
        "plt.imshow(X_test[idx], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj-pWLWM8svS"
      },
      "source": [
        "## 5. 완전히 새로운 데이터로 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px37hqeu8svS"
      },
      "source": [
        "# scissor_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
        "# rock_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
        "# paper_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
        "# test_path = paper_test_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
        "\n",
        "# colab\n",
        "paper_test = \"/content/drive/MyDrive/data/test/paper\"\n",
        "scissor_test = \"/content/drive/MyDrive/data/test/scissors\"\n",
        "rock_test = \"/content/drive/MyDrive/data/test/rock\"\n",
        "test_path = \"/content/drive/MyDrive/data/test\"\n",
        "\n",
        "test_paths = [scissor_test, rock_test, paper_test]\n",
        "\n",
        "# 새로운 데이터 리사이즈\n",
        "for path in test_paths:\n",
        "    resize_images(path) \n",
        "\n",
        "(X_new, y_new)=load_data(test_path)\n",
        "X_new_norm = X_new / 255.0\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_new_norm, y_new, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9qR4yK18svS"
      },
      "source": [
        "## 6. 더 좋은 네트워크 만들어보기\n",
        "- [x] 더 많은 데이터 추가하기\n",
        "- [x] Validation Set 만들기\n",
        "- [x] 하이퍼파라미터 변경\n",
        "- [x] 딥러닝 모델 바꾸기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnS6vmFa8svT"
      },
      "source": [
        "### 6-1. 이미지 보강"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l-NJSpg8svT"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "            rotation_range=10,\n",
        "            zoom_range=0.10,\n",
        "            shear_range=0.5,\n",
        "            width_shift_range=0.10,\n",
        "            height_shift_range=0.10,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=False)\n",
        "\n",
        "augment_size = 30000\n",
        "\n",
        "randidx = np.random.randint(X_train.shape[0], size=augment_size)\n",
        "x_augmented = X_train[randidx].copy()\n",
        "y_augmented = y_train[randidx].copy()\n",
        "x_augmented = image_generator.flow(x_augmented, np.zeros(augment_size),\n",
        "                                   batch_size=augment_size, shuffle=False).next()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cX_NJc_8svT"
      },
      "source": [
        "X_train = np.concatenate((X_train, x_augmented))\n",
        "y_train = np.concatenate((y_train, y_augmented))\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNxo3LKv8svT"
      },
      "source": [
        "### 6-2. 다시 학습 및 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je6m8zK_8svT"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 3), kernel_size=(3, 3), \n",
        "                           filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=256, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=25, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTPtF1Li8svT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], marker='.', c='red', label='Train-set Loss')\n",
        "plt.plot(history.history['val_loss'], marker='.', c='blue', label='Validation-set Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g--', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0, 1.2)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llv7MEdU8svT"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okLkrViB8svU"
      },
      "source": [
        "paper_test = \"/content/drive/MyDrive/data/test/paper\"\n",
        "scissor_test = \"/content/drive/MyDrive/data/test/scissors\"\n",
        "rock_test = \"/content/drive/MyDrive/data/test/rock\"\n",
        "test_path = \"/content/drive/MyDrive/data/test\"\n",
        "\n",
        "test_paths = [scissor_test, rock_test, paper_test]\n",
        "\n",
        "# 새로운 데이터 리사이즈\n",
        "for path in test_paths:\n",
        "    resize_images(path) \n",
        "\n",
        "(X_new, y_new)=load_data(test_path)\n",
        "X_new_norm = X_new / 255.0\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_new_norm, y_new, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNmzdf-t8svU"
      },
      "source": [
        "## 7. 결론(회고)\n",
        "\n",
        "- 책을 보고 공부하면서 많이 배웠는데 다음과 같은 내용들을 배웠다.\n",
        "    - Sequential model 만드는 방법\n",
        "    - 모델의 각 layer의 의미\n",
        "    - compile 옵션과 그 의미\n",
        "    - history와 history 그래프 그리기\n",
        "    - 이미지 보강하여 데이터 증폭 시키기\n",
        "  \n",
        "  \n",
        "- 평가 지표를 맞추기 위해 다음과 같은 시도를 했다.\n",
        "    - 더 많은 데이터 추가하기: 처음에 내가 찍은 사진 데이터 300장으로만 테스트 했는데 정확도 15%가 나왔었다. 이 후 사진을 더 추가하여 3000여장으로 늘렸다. 그 결과 정확도가 40% 정도 되었다.\n",
        "    - train, test 세트 나누기: 처음에는 train, test 셋으로 나누지 않고, 전체 데이터를 학습 시킨 후 완전 새로운 데이터로 테스트를 했었다. 이 방법 대신 train_test_split으로 train, test 셋을 나누어주었다. 그 결과 정확도가 70~80% 정도가 되었다. 완전 새로운 데이터보다는 정확도가 더 높게 나오게 된 것이다.\n",
        "    - Validation Set 만들기: train, test set 뿐만 아니라 validation set도 추가하였다. 이전에는 scikit-learn의 train_test_split을 두 번 사용해서 나눴었는데, tensorflow의 fit에 옵션을 validation_split 넣어주면서 간단히 validation set이 나누어 주었다.\n",
        "    - history 부분 추가: history를 이용해 그래프를 그림으로써 나의 모델이 무엇이 부족한지 한 눈에 보이도록 만들었다.\n",
        "    - 딥러닝 모델 바꾸기: 책을 보면서 컨벌루션 레이어, 풀링 레이어, 드롭 아웃 레이어 등을 추가 하였다. \n",
        "    - 하이퍼파라미터 변경: 하이퍼파라미터 부분은 손을 대면 댈수록 결과가 나빠져서 되도록 그대로 두었다. \n",
        "    - 이미지 데이터 증폭: 이 부분이 신기했다. 이미지들을 약간씩 수정해 데이터를 증폭시켜 이미지 데이터의 부족함을 극복하는 것이다. 그 결과 테스트 정확도가 100%가 되었다.\n",
        "- Tensorflow를 사실상 처음 사용해봤고 딥러닝에 대한 지식 특히 CNN에 대한 지식이 거의 없어서 많이 힘들었다. 이번 프로젝트에서 만든 모델의 각 부분이 무엇을 의미하는지는 알겠는데 왜 이렇게 레이어들을 쌓았고, 하이퍼파라미터 값은 왜 이 값으로 넣었는지는 아직 잘 모르겠다. CNN, Tensorflow에 대해 더 공부해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeskWgcWIi_U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}