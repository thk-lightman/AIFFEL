{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yihuoKWxoJrJ"
      },
      "source": [
        "# 미니 프로젝트 : 가위바위보 분류기를 만들자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z776fZ1oObz"
      },
      "source": [
        "## 1. 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIidF2sOoTD5"
      },
      "source": [
        "### 1-1. 데이터 만들기\n",
        "노트북 카메라를 이용하여 가위, 바위, 보 이미지 각 100장을 만들어본다. 구글의 teachable machine 사이트에서 쉽게 데이터를 만들 수 있다.\n",
        "\n",
        "[https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/)\n",
        "\n",
        "- 여러 각도에서 찍기\n",
        "- 여러 크기로 찍기\n",
        "- 여러 명이 찍기\n",
        "\n",
        "좋은 데이터가 좋은 결과를 낳는다.\n",
        "\n",
        "teachable machine을 통해서 이미지를 저장하면 이미지는 224x224 크기로 되어 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMw68b9CuGDa"
      },
      "source": [
        "### 1-2. 데이터 불러오기 + Resize 하기\n",
        "가위, 바위, 보 이미지를 28x28로 만들어야 한다. 이를 위해 `PIL` 라이브러리를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcqaQaNG8yy9"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YDI6IEM8yy-"
      },
      "source": [
        "import os\n",
        "\n",
        "IMG_SIZE = 28 # 이미지 사이즈\n",
        "total_image = 0 # 전체 이미지 개수\n",
        "\n",
        "# 이미지를 리사이즈 해주는 함수\n",
        "def resize_images(img_path):\n",
        "    images=glob.glob(img_path + \"/*.jpg\")\n",
        "    global total_image \n",
        "    total_image += len(images)\n",
        "    \n",
        "    print(f\"{len(images)} images will be resized.\")\n",
        "    \n",
        "    # resize all images to 28x28\n",
        "    target_size=(IMG_SIZE, IMG_SIZE) # 28x28 size\n",
        "    for img in images:\n",
        "        old_img=Image.open(img)\n",
        "        new_img=old_img.resize(target_size, Image.ANTIALIAS)\n",
        "        new_img.save(img, \"JPEG\")\n",
        "        \n",
        "    print(f\"{len(images)} images have been resized.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wS8eotJ8yy_"
      },
      "source": [
        "# Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mETiubX-mG-"
      },
      "source": [
        "# Colab\n",
        "paper_dir = \"/content/drive/MyDrive/data/train/paper\"\n",
        "rock_dir = \"/content/drive/MyDrive/data/train/rock\"\n",
        "scissor_dir = \"/content/drive/MyDrive/data/train/scissors\"\n",
        "train_data_path = \"/content/drive/MyDrive/data/train\"\n",
        "\n",
        "\n",
        "img_dir = [scissor_dir, rock_dir, paper_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgL_QIH88yzA"
      },
      "source": [
        "# scissor_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
        "# rock_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
        "# paper_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
        "# train_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "\n",
        "\n",
        "# img_dir = [scissor_dir, rock_dir, paper_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGMTykEH8yzB"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for image in tqdm(img_dir):\n",
        "    resize_images(image)\n",
        "    \n",
        "print(\"이미지 resize 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4IZ9R2T8yzC"
      },
      "source": [
        "# 총 이미지 개수\n",
        "print(total_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bie68bFR8yzD"
      },
      "source": [
        "### 1-3. 가위, 바위, 보 데이터를 읽는 `load_data()` 함수 만들기\n",
        "\n",
        "`load_data()` 함수는 입력으로 이미지가 있는 폴더 위치를 받는다. 여기서는 `rock_scissor_paper` 폴더 위치를 적어주면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv0CZHhe8yzD"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=300): \n",
        "    \"\"\"    \n",
        "    parameters:\n",
        "        img_path: The directory path of the rock_scissor_paper\n",
        "        number_of_data: The total nubmer of all images. Default value is 300.\n",
        "    return:\n",
        "        image data, label data\n",
        "    \"\"\"\n",
        "    # scissors: 0, rock: 1, paper: 2\n",
        "    img_size = IMG_SIZE\n",
        "    color = 3\n",
        "    \n",
        "    # image data\n",
        "    imgs = np.zeros(number_of_data * img_size * img_size * color, \n",
        "                    dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
        "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
        "    \n",
        "    idx = 0\n",
        "    for file in glob.iglob(img_path + '/scissors/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype=np.int32)\n",
        "        imgs[idx, :, :, :] = img # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx] = 0 # 가위 : 0\n",
        "        idx = idx + 1\n",
        "        \n",
        "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype=np.int32)\n",
        "        imgs[idx, :, :, :] = img # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx] = 1 # 바위 : 1\n",
        "        idx = idx + 1\n",
        "    \n",
        "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file), dtype=np.int32)\n",
        "        imgs[idx, :, :, :] = img # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx] = 2 # 보 : 2\n",
        "        idx = idx + 1\n",
        "        \n",
        "    print(f\"총 이미지 개수는 {idx} 입니다.\")\n",
        "    return imgs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9U8CS6O8yzE"
      },
      "source": [
        "# load data\n",
        "(X, y) = load_data(train_data_path, number_of_data=3207)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8IQbHUz8yzE"
      },
      "source": [
        "### 1-4. train, test data 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0PKC8av8yzF"
      },
      "source": [
        "# train data와 test data 나누어 주기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUBTHdQq8yzF"
      },
      "source": [
        "# 정규화\n",
        "X_train = X_train / 255.0   # 입력을 0~1 사이의 값으로 정규화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAMaVra88yzF"
      },
      "source": [
        "# 이미지 확인 (가위:0, 바위:1, 보:2)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_train[1000])\n",
        "print('라벨: ', y_train[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZo9p9g8yzF"
      },
      "source": [
        "## 2. 딥러닝 네트워크 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoR0oJU48yzG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 3), kernel_size=(3, 3), \n",
        "                           filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=256, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nas3FLbl9NuY"
      },
      "source": [
        "**합성곱 신경망(CNN)의 구조**\n",
        "1. 입력층: 입력 이미지 데이터가 최초로 거치게 되는 계층이다.\n",
        "2. 합성곱층(convolutional layer): 입력 데이터에서 특성을 추출하는 층이다.\n",
        "    - 입력 이미지가 들어왔을 떄 이미지에 대한 특성을 감시잫기 위해 커널(kernel)이나 필터(filter)를 사용한다. 커널/필터는 이미지의 모든 영역을 훑으면서 특성을 추출하게 되는데, 이렇게 추출된 결과물이 특성 맵(feature map)이다.\n",
        "3. 풀링층(pooling layer): 풀링층은 합성곱층과 유사하게 특성 맵의 차원을 다운 샘플링하여 연산량을 감소시키고, 주요한 벡터를 추출하여 학습을 효과적으로 할 수 있게 한다.\n",
        "4. 완전연결층(fully conneted layer)\n",
        "5. 드롭아웃(dropout): 신경망 모델이 과적합되는 것을 피하기 위한 방법으로, 학습 과정 중 임의로 일부 노드들을 학습에서 제외시킨다.\n",
        "6. 출력층(output layer): 소프트맥스 활성화 함수가 사용되는데, 입력받은 값을 0~1 사이의 값으로 출력한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIsS_oOLCCAt"
      },
      "source": [
        "**Conv**\n",
        "특성을 만든다.\n",
        "```python\n",
        "tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1))\n",
        "```\n",
        "- 첫 번째 파라미터: 합성곱 필터 개수\n",
        "- 두 번째 파라미터: 합성곱 커널의 해오가 열\n",
        "- `padding`: 경계 처리 방법\n",
        "    - `valid`: 유요한 영역만 출력되므로 출력 이미지 크기는 입력 이미지 크기보다 작다.\n",
        "    - `same`: 출력 이미지 크기가 입력 이미지 크기와 동일하다.\n",
        "- `activation`: 활성화 함수 설정\n",
        "    - `linear`: 기본값\n",
        "    - `relu`\n",
        "    - `sigmoid`\n",
        "    - `tanh`\n",
        "    - `softmax`\n",
        "- `input_shape`\n",
        "\n",
        "**Pooling**\n",
        "차원을 감소시킨다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gawKfuW8yzH"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8KQYKTn8yzH"
      },
      "source": [
        "## 3. 딥러닝 네트워크 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnOkSea98yzH"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZAomfuB9pZC"
      },
      "source": [
        "`compile()`에서 사용하는 주요 파라미터\n",
        "- `optimizer`: 옵티머이저란 손실 함수를 사용하여 구한 값으로 기울기를 구하고 네트워크의 파리미터를 학습에 어떻게 반영할지 결정하는 방법으로, 여기서는 `adam`을 사용한다.\n",
        "    - Adam은 Momoentum과 RMSProp의 장점을 결합한 경사 하강법이다.\n",
        "- `loss`: 최적화 과정에서 사용될 손실 함수(loss function)을 설정한다. 다수의 클래스를 분류하기 떄문에 `sparse_categorical_crossentropy` 손실 함수르 사용한다.\n",
        "- `metrics`: 모델의 평가 기준을 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixyO1VQA8yzH"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=25, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODg6R-Zw8yzH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], marker='.', c='red', label='Train-set Loss')\n",
        "plt.plot(history.history['val_loss'], marker='.', c='blue', label='Validation-set Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g--', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSe8YB7I8yzI"
      },
      "source": [
        "## 4. test 데이터로 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LUEoSVB8yzI"
      },
      "source": [
        "X_test = X_test / 255.0 # test data 정규화\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8VVbFiY8yzI"
      },
      "source": [
        "predicted_result = model.predict(X_test) # model이 추론한 확률값\n",
        "predicted_labels = np.argmax(predicted_result, axis=1) # 확률의 최대값이 예측하는 숫자를 뜻한다\n",
        "\n",
        "idx = 512\n",
        "print(f\"models.predict() 결과: {predicted_result[idx]}\\n\")\n",
        "print(f\"model이 추론한 가장 가능성이 높은 결과 : \", predicted_labels[idx])\n",
        "print(f\"실제 데이터의 라벨 : \", y_test[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "00w8zrix8yzI"
      },
      "source": [
        "# 실제 이미지 출력\n",
        "plt.imshow(X_test[idx], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy5bye3wGpWM"
      },
      "source": [
        "### 특성맵 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNiQWle1Fl-y"
      },
      "source": [
        "import cv2\n",
        "\n",
        "# 이미지 호출\n",
        "img = cv2.imread(paper_dir + r'/paper (100).jpg')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyQecLcqEg7a"
      },
      "source": [
        "# 특성맵 시각화\n",
        "import cv2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "ins = model.inputs # 모델의 입력 형태\n",
        "outs = model.layers[0].output # 첫 번째 계층에 대한 출력의 형태\n",
        "feature_map = Model(inputs=ins, outputs=outs) # 특성맵 정의\n",
        "feature_map.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp3yVjY7Govy"
      },
      "source": [
        "img = cv2.resize(img, (28, 28)) # 이미지 크기 조정\n",
        "input_img = np.expand_dims(img, axis=0)\n",
        "print(input_img.shape)\n",
        "\n",
        "# 특성 맵 확인\n",
        "feature = feature_map.predict(input_img) # 이미지를 모델에 적용\n",
        "print(feature.shape)\n",
        "fig = plt.figure(figsize=(50, 50))\n",
        "for i in range(16):\n",
        "    ax = fig.add_subplot(8, 4, i + 1)\n",
        "    ax.imshow(feature[0,:,:,i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Z8u_Rx8yzI"
      },
      "source": [
        "## 5. 완전히 새로운 데이터로 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjsrihf08yzI"
      },
      "source": [
        "# colab\n",
        "scissor_test = \"/content/drive/MyDrive/data/test/scissors\"\n",
        "rock_test = \"/content/drive/MyDrive/data/test/rock\"\n",
        "paper_test = \"/content/drive/MyDrive/data/test/paper\"\n",
        "test_path = \"/content/drive/MyDrive/data/test\"\n",
        "\n",
        "# scissor_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
        "# rock_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
        "# paper_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
        "# test_path = paper_test_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
        "\n",
        "test_paths = [scissor_test, rock_test, paper_test]\n",
        "\n",
        "# 새로운 데이터 리사이즈\n",
        "for path in test_paths:\n",
        "    resize_images(path) \n",
        "\n",
        "(X_new, y_new)=load_data(test_path)\n",
        "X_new_norm = X_new / 255.0\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_new_norm, y_new, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TapCpQ2t8yzI"
      },
      "source": [
        "## 6. 더 좋은 네트워크 만들어보기\n",
        "- [x] 더 많은 데이터 추가하기\n",
        "- [x] Validation Set 만들기\n",
        "- [x] 하이퍼파라미터 변경\n",
        "- [x] 딥러닝 모델 바꾸기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zgnpi5b8yzJ"
      },
      "source": [
        "### 6-1. 이미지 보강"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3HxsTxD8yzJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "            rotation_range=10,\n",
        "            zoom_range=0.10,\n",
        "            shear_range=0.5,\n",
        "            width_shift_range=0.10,\n",
        "            height_shift_range=0.10,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=False)\n",
        "\n",
        "augment_size = 30000\n",
        "\n",
        "randidx = np.random.randint(X_train.shape[0], size=augment_size)\n",
        "x_augmented = X_train[randidx].copy()\n",
        "y_augmented = y_train[randidx].copy()\n",
        "x_augmented = image_generator.flow(x_augmented, np.zeros(augment_size),\n",
        "                                   batch_size=augment_size, shuffle=False).next()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD0R4QvALiAV"
      },
      "source": [
        "**ImageDataGenerator**\n",
        "- `rescale`: 스케일링\n",
        "- `rotation_range`: 이미지 회전 범위\n",
        "- `width_shift_range`: 그림을 수평으로 랜덤하게 평행 이동 시키는 범위\n",
        "- `height_shift_range`: 그림을 수직으로 랜덤하게 평행 이동 시키는 범위\n",
        "- `shear_range`: 원본 이미지를 임의로 변형(전단) 시키는 범위. 0.5 라디안 내위로 시계 반대 방햐으로 이미지 변환\n",
        "- `zoom_range`: 임의 확대/축소 범위"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95oE0NBz8yzJ"
      },
      "source": [
        "X_train = np.concatenate((X_train, x_augmented))\n",
        "y_train = np.concatenate((y_train, y_augmented))\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Jvo_7C8yzJ"
      },
      "source": [
        "### 6-2. 다시 학습 및 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5RP5H5M8yzJ"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 3), kernel_size=(3, 3), \n",
        "                           filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=256, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=25, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRTVqh088yzJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], marker='.', c='red', label='Train-set Loss')\n",
        "plt.plot(history.history['val_loss'], marker='.', c='blue', label='Validation-set Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g--', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2EkCPqi8yzK"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW8FXu27Nfny"
      },
      "source": [
        "# colab\n",
        "scissor_test = \"/content/drive/MyDrive/data/test/scissors\"\n",
        "rock_test = \"/content/drive/MyDrive/data/test/rock\"\n",
        "paper_test = \"/content/drive/MyDrive/data/test/paper\"\n",
        "test_path = \"/content/drive/MyDrive/data/test\"\n",
        "\n",
        "# scissor_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
        "# rock_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
        "# paper_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
        "# test_path = paper_test_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
        "\n",
        "test_paths = [scissor_test, rock_test, paper_test]\n",
        "\n",
        "# 새로운 데이터 리사이즈\n",
        "for path in test_paths:\n",
        "    resize_images(path) \n",
        "\n",
        "(X_new, y_new)=load_data(test_path)\n",
        "X_new_norm = X_new / 255.0\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_new_norm, y_new, verbose=2)\n",
        "\n",
        "print(f\"test_loss: {test_loss}\")\n",
        "print(f\"test_accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAyaq_RJ8yzK"
      },
      "source": [
        "## 7. 결론(회고)\n",
        "\n",
        "- 책을 보고 공부하면서 많이 배웠는데 다음과 같은 내용들을 배웠다.\n",
        "    - Sequential model 만드는 방법\n",
        "    - 모델의 각 layer의 의미\n",
        "    - compile 옵션과 그 의미\n",
        "    - history와 history 그래프 그리기\n",
        "    - 이미지 보강하여 데이터 증폭 시키기\n",
        "  \n",
        "### 회고 1\n",
        "- 평가 지표를 맞추기 위해 다음과 같은 시도를 했다.\n",
        "    - 더 많은 데이터 추가하기: 처음에 내가 찍은 사진 데이터 300장으로만 테스트 했는데 정확도 15%가 나왔었다. 이 후 사진을 더 추가하여 3000여장으로 늘렸다. 그 결과 정확도가 40% 정도 되었다.\n",
        "    - train, test 세트 나누기: 처음에는 train, test 셋으로 나누지 않고, 전체 데이터를 학습 시킨 후 완전 새로운 데이터로 테스트를 했었다. 이 방법 대신 train_test_split으로 train, test 셋을 나누어주었다. 그 결과 정확도가 70~80% 정도가 되었다. 완전 새로운 데이터보다는 정확도가 더 높게 나오게 된 것이다.\n",
        "    - Validation Set 만들기: train, test set 뿐만 아니라 validation set도 추가하였다. 이전에는 scikit-learn의 train_test_split을 두 번 사용해서 나눴었는데, tensorflow의 fit에 옵션을 validation_split 넣어주면서 간단히 validation set이 나누어 주었다.\n",
        "    - history 부분 추가: history를 이용해 그래프를 그림으로써 나의 모델이 무엇이 부족한지 한 눈에 보이도록 만들었다.\n",
        "    - 딥러닝 모델 바꾸기: 책을 보면서 컨벌루션 레이어, 풀링 레이어, 드롭 아웃 레이어 등을 추가 하였다. \n",
        "    - 하이퍼파라미터 변경: 하이퍼파라미터 부분은 손을 대면 댈수록 결과가 나빠져서 되도록 그대로 두었다. \n",
        "    - 이미지 데이터 증폭: 이 부분이 신기했다. 이미지들을 약간씩 수정해 데이터를 증폭시켜 이미지 데이터의 부족함을 극복하는 것이다. 그 결과 테스트 정확도가 100%가 되었다.\n",
        "- Tensorflow를 사실상 처음 사용해봤고 딥러닝에 대한 지식 특히 CNN에 대한 지식이 거의 없어서 많이 힘들었다. 이번 프로젝트에서 만든 모델의 각 부분이 무엇을 의미하는지는 알겠는데 왜 이렇게 레이어들을 쌓았고, 하이퍼파라미터 값은 왜 이 값으로 넣었는지는 아직 잘 모르겠다. CNN, Tensorflow에 대해 더 공부해야 한다.\n",
        "\n",
        "### 회고 2\n",
        "추가적으로 CNN에 대한 학습을 한 후 여러가지 실험을 해봤다.\n",
        "+\n",
        "이미지를 증폭시키고 다시 테스트해본 결과 테스트 데이터의 정확도는 올랐으나, 완전히 새로운 데이터의 정확도는 오히려 소폭 하락을 하였다. 기존 데이터들에 대해서만 증폭시켜 모델이 기존 데이터들에 과적합이 된 것 같다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a-DXaHB8yzK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}